# LogiRAG Configuration Example
# Copy this file to config.yaml and fill in your settings

# LLM Configuration
llm:
  # Provider: openai, ollama, or any OpenAI-compatible API
  provider: openai
  
  # Your API key (required for OpenAI, optional for local models)
  api_key: "your-api-key-here"
  
  # API endpoint (change for local models or custom endpoints)
  api_base: "https://api.openai.com/v1"
  
  # Model name
  model: "gpt-4o"
  
  # Optional parameters
  temperature: 0.1
  max_tokens: 4096
  timeout: 60

# Indexer Configuration
indexer:
  add_node_id: true
  add_node_summary: true
  add_doc_description: true
  max_depth: 6

# Web Scraping Configuration
web:
  timeout: 30
  verify_ssl: true
  use_llm_for_conversion: true

# ===========================================
# Example Configurations for Different LLMs
# ===========================================

# --- OpenAI ---
# llm:
#   provider: openai
#   api_key: "sk-xxx"
#   api_base: "https://api.openai.com/v1"
#   model: "gpt-4o"

# --- Ollama (Local) ---
# llm:
#   provider: ollama
#   api_base: "http://localhost:11434/v1"
#   model: "llama3"

# --- DeepSeek ---
# llm:
#   provider: openai
#   api_key: "sk-xxx"
#   api_base: "https://api.deepseek.com/v1"
#   model: "deepseek-chat"

# --- Azure OpenAI ---
# llm:
#   provider: openai
#   api_key: "your-azure-key"
#   api_base: "https://your-resource.openai.azure.com/"
#   model: "gpt-4"

# --- vLLM / LocalAI / LM Studio ---
# llm:
#   provider: openai
#   api_key: "not-needed"
#   api_base: "http://localhost:8000/v1"
#   model: "your-local-model"

