"""
è°ƒè¯•å·¥å…·æ¨¡å— - æä¾›è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—è¾“å‡º
ç”¨äºè¿½è¸ª RAG ç³»ç»Ÿçš„å®Œæ•´è¿è¡Œæµç¨‹
"""

import logging
import json
import time
from typing import Any, Dict, List, Optional
from functools import wraps
from datetime import datetime

# é…ç½®è°ƒè¯•æ—¥å¿—æ ¼å¼
DEBUG_SEPARATOR = "=" * 80
DEBUG_SUBSEP = "-" * 60

# åˆ›å»ºä¸“ç”¨çš„è°ƒè¯• logger
debug_logger = logging.getLogger("logirag.debug")
debug_logger.setLevel(logging.DEBUG)

# ç¡®ä¿æœ‰å¤„ç†å™¨
if not debug_logger.handlers:
    handler = logging.StreamHandler()
    handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter(
        '\n%(asctime)s [DEBUG] %(message)s',
        datefmt='%H:%M:%S'
    )
    handler.setFormatter(formatter)
    debug_logger.addHandler(handler)


def debug_print(title: str, content: Any = None, level: str = "info"):
    """
    æ‰“å°è°ƒè¯•ä¿¡æ¯

    Args:
        title: æ ‡é¢˜
        content: å†…å®¹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€å­—å…¸ã€åˆ—è¡¨ç­‰ï¼‰
        level: æ—¥å¿—çº§åˆ« (info, success, warning, error)
    """
    level_icons = {
        "info": "â„¹ï¸",
        "success": "âœ…",
        "warning": "âš ï¸",
        "error": "âŒ",
        "start": "ğŸš€",
        "end": "ğŸ",
        "llm": "ğŸ¤–",
        "search": "ğŸ”",
        "result": "ğŸ“‹",
    }

    icon = level_icons.get(level, "ğŸ“Œ")

    print(f"\n{DEBUG_SEPARATOR}")
    print(f"{icon} {title}")
    print(DEBUG_SUBSEP)

    if content is not None:
        if isinstance(content, dict):
            print(json.dumps(content, indent=2, ensure_ascii=False, default=str))
        elif isinstance(content, list):
            for i, item in enumerate(content):
                if isinstance(item, dict):
                    print(f"[{i}] {json.dumps(item, indent=2, ensure_ascii=False, default=str)}")
                else:
                    print(f"[{i}] {item}")
        else:
            print(str(content))

    print(DEBUG_SEPARATOR)


def debug_request(endpoint: str, method: str, data: Dict):
    """è®°å½•ç”¨æˆ·è¯·æ±‚"""
    debug_print(
        f"ğŸ“¥ ç”¨æˆ·è¯·æ±‚ [{method}] {endpoint}",
        {
            "æ—¶é—´": datetime.now().isoformat(),
            "ç«¯ç‚¹": endpoint,
            "æ–¹æ³•": method,
            "è¯·æ±‚æ•°æ®": data
        },
        level="start"
    )


def debug_llm_call(purpose: str, prompt: str, system_prompt: str = None, model: str = None):
    """è®°å½• LLM è°ƒç”¨ - è¯·æ±‚"""
    content = {
        "ç›®çš„": purpose,
        "æ¨¡å‹": model or "æœªçŸ¥",
        "æ—¶é—´": datetime.now().isoformat(),
    }

    if system_prompt:
        content["ç³»ç»Ÿæç¤ºè¯"] = system_prompt[:500] + "..." if len(system_prompt) > 500 else system_prompt

    content["ç”¨æˆ·æç¤ºè¯"] = prompt[:2000] + "..." if len(prompt) > 2000 else prompt

    debug_print(f"ğŸ¤– LLM è°ƒç”¨è¯·æ±‚ - {purpose}", content, level="llm")


def debug_llm_response(purpose: str, response: str, usage: Dict = None, duration: float = None):
    """è®°å½• LLM è°ƒç”¨ - å“åº”"""
    content = {
        "ç›®çš„": purpose,
        "å“åº”é•¿åº¦": len(response) if response else 0,
    }

    if duration:
        content["è€—æ—¶"] = f"{duration:.2f}ç§’"

    if usage:
        content["Token ä½¿ç”¨"] = usage

    # æ˜¾ç¤ºå®Œæ•´å“åº”æˆ–æˆªæ–­
    if response:
        content["å“åº”å†…å®¹"] = response[:3000] + "..." if len(response) > 3000 else response

    debug_print(f"ğŸ¤– LLM è°ƒç”¨å“åº” - {purpose}", content, level="llm")


def debug_rag_search_start(query: str, mode: str, documents_count: int):
    """è®°å½• RAG æœç´¢å¼€å§‹"""
    debug_print(
        "ğŸ” RAG æœç´¢å¼€å§‹",
        {
            "æŸ¥è¯¢": query,
            "æ£€ç´¢æ¨¡å¼": mode,
            "æ–‡æ¡£æ•°é‡": documents_count,
            "æ—¶é—´": datetime.now().isoformat()
        },
        level="search"
    )


def debug_vector_search(query: str, top_k: int, results: List, duration: float = None):
    """è®°å½•å‘é‡æœç´¢ç»“æœ"""
    result_summary = []
    for r in results[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
        result_summary.append({
            "æ–‡æ¡£": getattr(r, 'doc_name', 'unknown'),
            "èŠ‚ç‚¹ID": getattr(r, 'node_id', 'unknown'),
            "æ ‡é¢˜": getattr(r, 'title', 'unknown'),
            "åˆ†æ•°": round(getattr(r, 'score', 0), 4)
        })

    debug_print(
        "ğŸ” å‘é‡æœç´¢ç»“æœ",
        {
            "æŸ¥è¯¢": query[:100],
            "è¯·æ±‚æ•°é‡": top_k,
            "è¿”å›æ•°é‡": len(results),
            "è€—æ—¶": f"{duration:.2f}ç§’" if duration else "æœªçŸ¥",
            "ç»“æœåˆ—è¡¨": result_summary
        },
        level="search"
    )


def debug_reasoning_round(round_num: int, candidates_count: int, prompt: str, response: str):
    """è®°å½•æ¨ç†è½®æ¬¡"""
    debug_print(
        f"ğŸ§  æ¨ç†ç¬¬ {round_num} è½®",
        {
            "å€™é€‰èŠ‚ç‚¹æ•°": candidates_count,
            "æç¤ºè¯": prompt[:1500] + "..." if len(prompt) > 1500 else prompt,
            "LLM å“åº”": response[:1500] + "..." if len(response) > 1500 else response
        },
        level="llm"
    )


def debug_rag_results(results: List, mode: str, duration: float = None):
    """è®°å½• RAG æœç´¢ç»“æœ"""
    result_summary = []
    for r in results[:10]:
        if hasattr(r, 'doc_name'):
            # HybridSearchResult æˆ– SearchResult
            result_summary.append({
                "æ–‡æ¡£": r.doc_name,
                "èŠ‚ç‚¹ID": r.node_id,
                "æ ‡é¢˜": getattr(r, 'title', 'unknown'),
                "æœ€ç»ˆåˆ†æ•°": round(getattr(r, 'final_score', getattr(r, 'relevance_score', 0)), 4),
                "å‘é‡åˆ†æ•°": round(getattr(r, 'vector_score', 0) or 0, 4),
                "æ¨ç†åˆ†æ•°": round(getattr(r, 'reasoning_score', 0) or 0, 4),
                "æ¥æº": getattr(r, 'source', mode),
                "ç†ç”±": getattr(r, 'reasoning', '')[:100]
            })
        elif isinstance(r, dict):
            result_summary.append({
                "æ–‡æ¡£": r.get('doc_name', 'unknown'),
                "èŠ‚ç‚¹ID": r.get('node_id', 'unknown'),
                "ç›¸å…³åº¦": round(r.get('relevance', 0), 4)
            })

    debug_print(
        "ğŸ“‹ RAG æœç´¢ç»“æœæ±‡æ€»",
        {
            "æ£€ç´¢æ¨¡å¼": mode,
            "ç»“æœæ•°é‡": len(results),
            "è€—æ—¶": f"{duration:.2f}ç§’" if duration else "æœªçŸ¥",
            "å‘½ä¸­åˆ—è¡¨": result_summary
        },
        level="result"
    )


def debug_context_retrieval(contexts: List[Dict]):
    """è®°å½•ä¸Šä¸‹æ–‡æå–"""
    context_summary = []
    total_chars = 0

    for ctx in contexts:
        content = ctx.get('content', '')
        content_len = len(content)
        total_chars += content_len
        context_summary.append({
            "æ–‡æ¡£": ctx.get('doc_name', 'unknown'),
            "èŠ‚ç‚¹ID": ctx.get('node_id', 'unknown'),
            "æ ‡é¢˜": ctx.get('title', 'unknown'),
            "å†…å®¹é•¿åº¦": content_len,
            "ç›¸å…³åº¦": round(ctx.get('relevance', 0), 4),
            "å†…å®¹é¢„è§ˆ": content[:200] + "..." if len(content) > 200 else content
        })

    debug_print(
        "ğŸ“š ä¸Šä¸‹æ–‡æå–ç»“æœ",
        {
            "æå–èŠ‚ç‚¹æ•°": len(contexts),
            "æ€»å­—ç¬¦æ•°": total_chars,
            "ä¼°è®¡Token": total_chars // 3,
            "èŠ‚ç‚¹è¯¦æƒ…": context_summary
        },
        level="result"
    )


def debug_chat_response(query: str, response: str, context_used: bool, duration: float = None):
    """è®°å½•èŠå¤©å“åº”"""
    debug_print(
        "ğŸ’¬ èŠå¤©å“åº”ç”Ÿæˆ",
        {
            "ç”¨æˆ·é—®é¢˜": query,
            "ä½¿ç”¨çŸ¥è¯†åº“": "æ˜¯" if context_used else "å¦",
            "å“åº”é•¿åº¦": len(response),
            "è€—æ—¶": f"{duration:.2f}ç§’" if duration else "æœªçŸ¥",
            "å“åº”å†…å®¹": response
        },
        level="end"
    )


def debug_response(endpoint: str, status: str, data: Dict, duration: float = None):
    """è®°å½•æœ€ç»ˆå“åº”"""
    summary = {
        "ç«¯ç‚¹": endpoint,
        "çŠ¶æ€": status,
        "è€—æ—¶": f"{duration:.2f}ç§’" if duration else "æœªçŸ¥",
    }

    # æ·»åŠ å…³é”®å“åº”æ•°æ®çš„æ‘˜è¦
    if 'context' in data:
        summary["ä¸Šä¸‹æ–‡é•¿åº¦"] = len(data.get('context', ''))
    if 'nodes' in data:
        summary["å‘½ä¸­èŠ‚ç‚¹æ•°"] = len(data.get('nodes', []))
    if 'source_files' in data:
        summary["æ¥æºæ–‡æ¡£"] = data.get('source_files', [])
    if 'mode' in data:
        summary["æ£€ç´¢æ¨¡å¼"] = data.get('mode')
    if 'thinking' in data:
        thinking = data.get('thinking', '')
        summary["æ¨ç†è¿‡ç¨‹"] = thinking[:500] + "..." if len(thinking) > 500 else thinking

    debug_print(f"ğŸ“¤ å“åº”å®Œæˆ - {endpoint}", summary, level="end")


class DebugTimer:
    """è°ƒè¯•è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, name: str):
        self.name = name
        self.start_time = None
        self.duration = None

    def __enter__(self):
        self.start_time = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.duration = time.time() - self.start_time
        return False

    def elapsed(self) -> float:
        if self.duration is not None:
            return self.duration
        return time.time() - self.start_time


def debug_decorator(name: str):
    """è°ƒè¯•è£…é¥°å™¨ - è®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´å’Œå‚æ•°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            debug_print(f"â±ï¸ å¼€å§‹æ‰§è¡Œ: {name}", {"å‚æ•°": str(kwargs)[:500]}, level="start")
            start = time.time()
            try:
                result = func(*args, **kwargs)
                duration = time.time() - start
                debug_print(f"â±ï¸ æ‰§è¡Œå®Œæˆ: {name}", {"è€—æ—¶": f"{duration:.2f}ç§’"}, level="end")
                return result
            except Exception as e:
                duration = time.time() - start
                debug_print(f"â±ï¸ æ‰§è¡Œå¤±è´¥: {name}", {"é”™è¯¯": str(e), "è€—æ—¶": f"{duration:.2f}ç§’"}, level="error")
                raise
        return wrapper
    return decorator
