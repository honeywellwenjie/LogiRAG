"""
è°ƒè¯•å·¥å…·æ¨¡å— - æä¾›è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—è¾“å‡º
ç”¨äºè¿½è¸ª RAG ç³»ç»Ÿçš„å®Œæ•´è¿è¡Œæµç¨‹

ä¼˜åŒ–ç›®æ ‡ï¼š
- å¯è¯»æ€§ï¼šJSON æ ¼å¼åŒ–æ˜¾ç¤ºï¼Œæ¢è¡Œç¬¦æ­£ç¡®æ¸²æŸ“
- ç®€æ´æ€§ï¼šå»é™¤æ—¶é—´æˆ³ï¼Œèšç„¦å…³é”®ä¿¡æ¯
- æ˜ç¡®æ€§ï¼šæ¸…æ™°å±•ç¤ºæ··åˆæ¨¡å¼å„é˜¶æ®µå‘½ä¸­æƒ…å†µ
"""

import logging
import json
import re
import time
from typing import Any, Dict, List, Optional
from functools import wraps

# é…ç½®è°ƒè¯•æ—¥å¿—æ ¼å¼
DEBUG_SEPARATOR = "=" * 70
DEBUG_SUBSEP = "-" * 50

# åˆ›å»ºä¸“ç”¨çš„è°ƒè¯• loggerï¼ˆæ— æ—¶é—´æˆ³ï¼‰
debug_logger = logging.getLogger("logirag.debug")
debug_logger.setLevel(logging.DEBUG)

# ç¡®ä¿æœ‰å¤„ç†å™¨
if not debug_logger.handlers:
    handler = logging.StreamHandler()
    handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter('\n[DEBUG] %(message)s')
    handler.setFormatter(formatter)
    debug_logger.addHandler(handler)


def _format_json_readable(data: Any, indent: int = 2) -> str:
    """
    å°†æ•°æ®æ ¼å¼åŒ–ä¸ºå¯è¯»çš„æ ¼å¼
    - JSON å­—ç¬¦ä¸²ä¸­çš„ \\n è½¬ä¸ºçœŸæ­£çš„æ¢è¡Œ
    - ç§»é™¤å¤šä½™çš„è½¬ä¹‰ç¬¦å·
    """
    if data is None:
        return "null"

    try:
        # å…ˆè½¬ä¸º JSON å­—ç¬¦ä¸²
        json_str = json.dumps(data, indent=indent, ensure_ascii=False, default=str)
        # ä¸åšé¢å¤–å¤„ç†ï¼Œä¿æŒ JSON æ ¼å¼
        return json_str
    except Exception:
        return str(data)


def _format_llm_response(response: str) -> str:
    """
    æ ¼å¼åŒ– LLM å“åº”ï¼Œä½¿å…¶æ›´å¯è¯»
    - æå–å¹¶æ ¼å¼åŒ– JSON å—
    - æ¢è¡Œç¬¦æ­£ç¡®æ˜¾ç¤º
    """
    if not response:
        return "(ç©ºå“åº”)"

    # å°è¯•æå– JSON å—
    json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
    if json_match:
        json_str = json_match.group(1)
        try:
            parsed = json.loads(json_str)
            return _format_parsed_llm_json(parsed)
        except json.JSONDecodeError:
            pass

    # å°è¯•ç›´æ¥è§£æä¸º JSON
    try:
        parsed = json.loads(response)
        return _format_parsed_llm_json(parsed)
    except json.JSONDecodeError:
        pass

    # æ™®é€šæ–‡æœ¬ï¼šæ¢è¡Œç¬¦æ­£ç¡®æ˜¾ç¤º
    return response.replace('\\n', '\n')


def _format_parsed_llm_json(parsed: dict) -> str:
    """æ ¼å¼åŒ–è§£æåçš„ LLM JSON å“åº”"""
    lines = []

    # åˆ†æéƒ¨åˆ†
    if 'analysis' in parsed:
        lines.append("ã€åˆ†æã€‘")
        lines.append(parsed['analysis'])
        lines.append("")

    # å€™é€‰èŠ‚ç‚¹
    if 'candidates' in parsed:
        lines.append("ã€å€™é€‰èŠ‚ç‚¹ã€‘")
        for i, c in enumerate(parsed['candidates'], 1):
            doc = c.get('doc_name', 'unknown')
            node = c.get('node_id', 'unknown')
            rel = c.get('relevance', 0)
            reason = c.get('reason', '')
            lines.append(f"  {i}. [{doc}:{node}] ç›¸å…³åº¦={rel}")
            if reason:
                lines.append(f"     åŸå› : {reason[:100]}...")
        lines.append("")

    # é€‰ä¸­èŠ‚ç‚¹
    if 'selected_nodes' in parsed:
        lines.append("ã€é€‰ä¸­èŠ‚ç‚¹ã€‘")
        for i, s in enumerate(parsed['selected_nodes'], 1):
            node = s.get('node_id', 'unknown')
            rel = s.get('relevance', 0)
            reason = s.get('reason', '')
            lines.append(f"  {i}. [{node}] ç›¸å…³åº¦={rel}")
            if reason:
                lines.append(f"     åŸå› : {reason[:100]}...")
        lines.append("")

    if lines:
        return '\n'.join(lines)
    else:
        # å›é€€åˆ°æ ¼å¼åŒ– JSON
        return json.dumps(parsed, indent=2, ensure_ascii=False)


def debug_print(title: str, content: Any = None, level: str = "info"):
    """
    æ‰“å°è°ƒè¯•ä¿¡æ¯

    Args:
        title: æ ‡é¢˜
        content: å†…å®¹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€å­—å…¸ã€åˆ—è¡¨ç­‰ï¼‰
        level: æ—¥å¿—çº§åˆ« (info, success, warning, error, start, end, llm, search, result)
    """
    level_icons = {
        "info": "â„¹ï¸ ",
        "success": "âœ…",
        "warning": "âš ï¸ ",
        "error": "âŒ",
        "start": "ğŸš€",
        "end": "ğŸ",
        "llm": "ğŸ¤–",
        "search": "ğŸ”",
        "result": "ğŸ“‹",
        "vector": "ğŸ“Š",
        "hybrid": "ğŸ”€",
    }

    icon = level_icons.get(level, "ğŸ“Œ")

    print(f"\n{DEBUG_SEPARATOR}")
    print(f"{icon} {title}")
    print(DEBUG_SUBSEP)

    if content is not None:
        if isinstance(content, dict):
            _print_dict_readable(content)
        elif isinstance(content, list):
            for i, item in enumerate(content):
                if isinstance(item, dict):
                    print(f"[{i}]")
                    _print_dict_readable(item, indent=2)
                else:
                    print(f"[{i}] {item}")
        else:
            print(str(content))

    print(DEBUG_SEPARATOR)


def _print_dict_readable(d: dict, indent: int = 0):
    """å¯è¯»åœ°æ‰“å°å­—å…¸ï¼Œç‰¹æ®Šå¤„ç† LLM å“åº”"""
    prefix = " " * indent

    for key, value in d.items():
        if key in ("LLM å“åº”", "å“åº”å†…å®¹", "LLMå“åº”") and isinstance(value, str):
            # ç‰¹æ®Šå¤„ç† LLM å“åº”
            print(f"{prefix}{key}:")
            formatted = _format_llm_response(value)
            for line in formatted.split('\n'):
                print(f"{prefix}  {line}")
        elif key in ("ç”¨æˆ·æç¤ºè¯", "ç³»ç»Ÿæç¤ºè¯", "æç¤ºè¯") and isinstance(value, str):
            # æç¤ºè¯ï¼šæ˜¾ç¤ºå‰200å­—ç¬¦
            preview = value[:200] + "..." if len(value) > 200 else value
            print(f"{prefix}{key}: {preview}")
        elif isinstance(value, dict):
            print(f"{prefix}{key}:")
            _print_dict_readable(value, indent + 2)
        elif isinstance(value, list):
            if len(value) == 0:
                print(f"{prefix}{key}: []")
            elif all(isinstance(x, dict) for x in value):
                print(f"{prefix}{key}:")
                for i, item in enumerate(value):
                    print(f"{prefix}  [{i}]")
                    _print_dict_readable(item, indent + 4)
            else:
                print(f"{prefix}{key}: {value}")
        else:
            print(f"{prefix}{key}: {value}")


def debug_llm_call(purpose: str, prompt: str, system_prompt: str = None, model: str = None):
    """è®°å½• LLM è°ƒç”¨ - è¯·æ±‚ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    print(f"\n{DEBUG_SUBSEP}")
    print(f"ğŸ¤– LLM è¯·æ±‚: {purpose}")
    print(f"   æ¨¡å‹: {model or 'æœªçŸ¥'}")
    print(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(DEBUG_SUBSEP)


def debug_llm_response(purpose: str, response: str, usage: Dict = None, duration: float = None):
    """è®°å½• LLM è°ƒç”¨ - å“åº”ï¼ˆæ ¼å¼åŒ–æ˜¾ç¤ºï¼‰"""
    print(f"\n{DEBUG_SUBSEP}")
    print(f"ğŸ¤– LLM å“åº”: {purpose}")
    if duration:
        print(f"   è€—æ—¶: {duration:.2f}ç§’")
    if usage:
        print(f"   Token: {usage}")
    print(DEBUG_SUBSEP)

    # æ ¼å¼åŒ–æ˜¾ç¤ºå“åº”å†…å®¹
    formatted = _format_llm_response(response)
    print(formatted)
    print(DEBUG_SUBSEP)


def debug_rag_search_start(query: str, mode: str, documents_count: int):
    """è®°å½• RAG æœç´¢å¼€å§‹"""
    print(f"\n{'=' * 70}")
    print(f"ğŸ” RAG æœç´¢å¼€å§‹")
    print(f"   æŸ¥è¯¢: {query}")
    print(f"   æ¨¡å¼: {mode}")
    print(f"   æ–‡æ¡£æ•°: {documents_count}")
    print(f"{'=' * 70}")


def debug_vector_search(query: str, top_k: int, results: List, duration: float = None):
    """è®°å½•å‘é‡æœç´¢ç»“æœï¼ˆè¯¦ç»†ç‰ˆï¼‰"""
    print(f"\n{DEBUG_SEPARATOR}")
    print(f"ğŸ“Š å‘é‡æœç´¢å®Œæˆ")
    print(DEBUG_SUBSEP)
    print(f"   æŸ¥è¯¢: {query[:50]}...")
    print(f"   è¯·æ±‚ top_k: {top_k}")
    print(f"   è¿”å›æ•°é‡: {len(results)}")
    if duration:
        print(f"   è€—æ—¶: {duration:.3f}ç§’")
    print(DEBUG_SUBSEP)

    if results:
        print("   å‘½ä¸­èŠ‚ç‚¹:")
        for i, r in enumerate(results[:10], 1):
            doc = getattr(r, 'doc_name', 'unknown')
            node = getattr(r, 'node_id', 'unknown')
            title = getattr(r, 'title', 'unknown')
            score = getattr(r, 'score', 0)
            print(f"   {i:2d}. [{doc}:{node}] score={score:.4f}")
            print(f"       æ ‡é¢˜: {title[:40]}...")
    else:
        print("   (æ— å‘½ä¸­ç»“æœ)")
    print(DEBUG_SEPARATOR)


def debug_reasoning_round(round_num: int, candidates_count: int, prompt: str, response: str):
    """è®°å½•æ¨ç†è½®æ¬¡ï¼ˆæ ¼å¼åŒ– LLM å“åº”ï¼‰"""
    print(f"\n{DEBUG_SEPARATOR}")
    print(f"ğŸ§  æ¨ç†ç¬¬ {round_num} è½®")
    print(DEBUG_SUBSEP)
    print(f"   å€™é€‰èŠ‚ç‚¹æ•°: {candidates_count}")
    print(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(DEBUG_SUBSEP)
    print("LLM å“åº”:")
    formatted = _format_llm_response(response)
    print(formatted)
    print(DEBUG_SEPARATOR)


def debug_rag_results(results: List, mode: str, duration: float = None):
    """è®°å½• RAG æœç´¢ç»“æœï¼ˆæ··åˆæ¨¡å¼è¯¦ç»†ç‰ˆï¼‰"""
    print(f"\n{'=' * 70}")
    print(f"ğŸ“‹ RAG æœç´¢ç»“æœæ±‡æ€»")
    print(f"{'=' * 70}")
    print(f"   æ£€ç´¢æ¨¡å¼: {mode}")
    print(f"   ç»“æœæ•°é‡: {len(results)}")
    if duration:
        print(f"   æ€»è€—æ—¶: {duration:.2f}ç§’")
    print(DEBUG_SUBSEP)

    if results:
        print("å‘½ä¸­è¯¦æƒ…:")
        print(f"{'åºå·':<4} {'æ–‡æ¡£':<25} {'èŠ‚ç‚¹':<8} {'æœ€ç»ˆåˆ†':<8} {'å‘é‡åˆ†':<8} {'æ¨ç†åˆ†':<8} {'æ¥æº':<8}")
        print("-" * 70)

        for i, r in enumerate(results[:10], 1):
            if hasattr(r, 'doc_name'):
                doc = r.doc_name[:24]
                node = r.node_id
                final = getattr(r, 'final_score', getattr(r, 'relevance_score', 0))
                vec = getattr(r, 'vector_score', None)
                reas = getattr(r, 'reasoning_score', None)
                source = getattr(r, 'source', mode)

                vec_str = f"{vec:.4f}" if vec else "-"
                reas_str = f"{reas:.4f}" if reas else "-"

                print(f"{i:<4} {doc:<25} {node:<8} {final:<8.4f} {vec_str:<8} {reas_str:<8} {source:<8}")

                # æ˜¾ç¤ºæ¨ç†åŸå› ï¼ˆå¦‚æœæœ‰ï¼‰
                reasoning = getattr(r, 'reasoning', '')
                if reasoning:
                    print(f"     åŸå› : {reasoning[:60]}...")
    else:
        print("   (æ— å‘½ä¸­ç»“æœ)")

    print(f"{'=' * 70}")


def debug_hybrid_stage(stage: str, info: dict):
    """è®°å½•æ··åˆæœç´¢çš„å„ä¸ªé˜¶æ®µ"""
    stage_icons = {
        "vector_start": "ğŸ“Š å‘é‡é¢„è¿‡æ»¤å¼€å§‹",
        "vector_done": "ğŸ“Š å‘é‡é¢„è¿‡æ»¤å®Œæˆ",
        "filter_docs": "ğŸ“ æ–‡æ¡£è¿‡æ»¤",
        "reasoning_start": "ğŸ§  LLMæ¨ç†å¼€å§‹",
        "reasoning_done": "ğŸ§  LLMæ¨ç†å®Œæˆ",
        "fusion": "ğŸ”€ ç»“æœèåˆ",
        "final": "âœ… æœ€ç»ˆç»“æœ",
    }

    title = stage_icons.get(stage, f"ğŸ“Œ {stage}")
    print(f"\n{DEBUG_SUBSEP}")
    print(f"{title}")

    for key, value in info.items():
        if isinstance(value, list) and len(value) > 5:
            print(f"   {key}: [{len(value)} é¡¹]")
            for item in value[:3]:
                print(f"     - {item}")
            print(f"     ... è¿˜æœ‰ {len(value) - 3} é¡¹")
        else:
            print(f"   {key}: {value}")

    print(DEBUG_SUBSEP)


def debug_context_retrieval(contexts: List[Dict]):
    """è®°å½•ä¸Šä¸‹æ–‡æå–"""
    total_chars = sum(len(ctx.get('content', '')) for ctx in contexts)

    print(f"\n{DEBUG_SEPARATOR}")
    print(f"ğŸ“š ä¸Šä¸‹æ–‡æå–ç»“æœ")
    print(DEBUG_SUBSEP)
    print(f"   æå–èŠ‚ç‚¹æ•°: {len(contexts)}")
    print(f"   æ€»å­—ç¬¦æ•°: {total_chars}")
    print(f"   ä¼°è®¡Token: {total_chars // 3}")
    print(DEBUG_SUBSEP)

    for i, ctx in enumerate(contexts[:5], 1):
        doc = ctx.get('doc_name', 'unknown')
        node = ctx.get('node_id', 'unknown')
        title = ctx.get('title', 'unknown')
        rel = ctx.get('relevance', 0)
        content = ctx.get('content', '')

        print(f"{i}. [{doc}:{node}] ç›¸å…³åº¦={rel:.4f}")
        print(f"   æ ‡é¢˜: {title}")
        print(f"   å†…å®¹: {content[:100]}...")
        print()

    print(DEBUG_SEPARATOR)


def debug_chat_response(query: str, response: str, context_used: bool, duration: float = None):
    """è®°å½•èŠå¤©å“åº”"""
    print(f"\n{DEBUG_SEPARATOR}")
    print(f"ğŸ’¬ èŠå¤©å“åº”ç”Ÿæˆ")
    print(DEBUG_SUBSEP)
    print(f"   ç”¨æˆ·é—®é¢˜: {query}")
    print(f"   ä½¿ç”¨çŸ¥è¯†åº“: {'æ˜¯' if context_used else 'å¦'}")
    print(f"   å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
    if duration:
        print(f"   è€—æ—¶: {duration:.2f}ç§’")
    print(DEBUG_SUBSEP)
    print("å“åº”å†…å®¹:")
    print(response)
    print(DEBUG_SEPARATOR)


def debug_response(endpoint: str, status: str, data: Dict, duration: float = None):
    """è®°å½•æœ€ç»ˆå“åº”"""
    print(f"\n{DEBUG_SEPARATOR}")
    print(f"ğŸ“¤ å“åº”å®Œæˆ - {endpoint}")
    print(DEBUG_SUBSEP)
    print(f"   çŠ¶æ€: {status}")
    if duration:
        print(f"   è€—æ—¶: {duration:.2f}ç§’")

    if 'context' in data:
        print(f"   ä¸Šä¸‹æ–‡é•¿åº¦: {len(data.get('context', ''))} å­—ç¬¦")
    if 'nodes' in data:
        print(f"   å‘½ä¸­èŠ‚ç‚¹æ•°: {len(data.get('nodes', []))}")
    if 'source_files' in data:
        print(f"   æ¥æºæ–‡æ¡£: {data.get('source_files', [])}")
    if 'mode' in data:
        print(f"   æ£€ç´¢æ¨¡å¼: {data.get('mode')}")

    print(DEBUG_SEPARATOR)


class DebugTimer:
    """è°ƒè¯•è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, name: str):
        self.name = name
        self.start_time = None
        self.duration = None

    def __enter__(self):
        self.start_time = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.duration = time.time() - self.start_time
        return False

    def elapsed(self) -> float:
        if self.duration is not None:
            return self.duration
        return time.time() - self.start_time


def debug_decorator(name: str):
    """è°ƒè¯•è£…é¥°å™¨ - è®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            print(f"\nâ±ï¸  å¼€å§‹: {name}")
            start = time.time()
            try:
                result = func(*args, **kwargs)
                duration = time.time() - start
                print(f"â±ï¸  å®Œæˆ: {name} ({duration:.2f}ç§’)")
                return result
            except Exception as e:
                duration = time.time() - start
                print(f"â±ï¸  å¤±è´¥: {name} ({duration:.2f}ç§’) - {e}")
                raise
        return wrapper
    return decorator
